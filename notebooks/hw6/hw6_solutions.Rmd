---
title: "STAT 8830 HW6"
output:
  pdf_document: default
  html_notebook: default
---

# 1) Finding best k for k-nearest neighbors with LOOCV

Here we want to define a function to apply the $k$-nearest neighbors algorithm to a labeled dataset and find the optimal value of $k$ with leave-one-out cross-validation: that is the value of $k$ which yields the best estimates, on average, when a single value is masked and predicted using the rest of the training set. Given a set of labeled pairs $(X_i, Y_i)$, $i \in {1, ..., n}$, $k$ can range from $1$ to $n - 1$. We exhaustively test all possibilities and select the one that maximizes correct predictions on the training set.

```{r}
library(plyr)
library(ggplot2)
library(class)

KNNcv = function(train, test, cl) {
  ks = seq(1, nrow(train) - 1)
  props_correct = c()
  
  # loop over all values of k, perform LOOCV, count proportion of correct predictions
  for (k in ks) {
    num_correct = 0
    # loop over rows and validate with each one
    for (i in 1:nrow(train)) {
      real = cl[i]
      pred = knn(train[-i,], train[i,], cl=cl[-i], k=k)
      if (pred == real) num_correct = num_correct + 1
    }
    props_correct = c(props_correct, num_correct / nrow(train))
    
    # for debugging
    # print(paste(num_correct, 'correct for k =', k))
  }
  
  # if multiple values of k are tied for optimal, just pick one randomly
  best_k = which.max(props_correct)
  best_prop = props_correct[best_k]
  
  # for debugging
  # print(paste0('Best k=', best_k, ' with ', round(best_prop, digits = 2) * 100, '% correct'))
  
  # fit knn to test data and return predictions and best k
  list(knn(train, test, cl, best_k), best_k)
}
```

First, generate a dataset with 3 normally distributed clusters.

```{r}
library(MASS)
library(gmodels)
library(ggplot2)

set.seed(24)

n = 100  # points per cluster
mu_x1 = 10
mu_y1 = 10
mu_x2 = 30
mu_y2 = 10
mu_x3 = 30
mu_y3 = 30
sd = 60
d1 = mvrnorm(n, mu=c(mu_x1, mu_y1), Sigma=sd * diag(2))
d2 = mvrnorm(n, mu=c(mu_x2, mu_y2), Sigma=sd * diag(2))
d3 = mvrnorm(n, mu=c(mu_x3, mu_y3), Sigma=sd * diag(2))
d = rbind(d1, d2, d3)
d = cbind(d, c(rep(1, n), rep(2, n), rep(3, n)))
colnames(d) = c('x', 'y', 'category')
plot(d[,1:2], col=d[,3], xlab="X1", ylab="X2", main="Sample Data", pch=16)
legend("bottomright", c("category 1", "category 2", "category 3"), col=1:3, pch=16)
```

Split the data into subsets for training and testing.

```{r}
train = sample(1:nrow(d), nrow(d) / 2)
d.train = d[train,]
d.test = d[-train,]
```

Now run the simulation function.

```{r}
result = KNNcv(d.train[, c("x", "y")], d.test[, c("x", "y")], d.train[, 'category'])
test_preds = result[[1]]
best_k = result[[2]]

print(paste0('KNN with k=', best_k, ' got ', round(sum(test_preds == d.test[, 'category']) / nrow(d.test), digits = 2) * 100, '% correct'))
plot(d.test[, c("x")], d.test[, c("y")], xlab = 'X', ylab = 'Y', pch = as.numeric(d.test[, 'category']) + 1, main = paste('Predictions for k =', best_k))
legend(x = 'topleft', legend = c("Correct", "Incorrect"),  fill = c("green", "red"))
points(d.test[, c("x", "y")], col = ifelse(test_preds == d.test[, 'category'], 'springgreen3', 'tomato'))
```

# 2) Comparison of LDA, KNN, and tree classification

Here we want to compare the accuracy of LDA, KNN, and tree classification.

First we generate a test dataset with 2 classes. To generate complex boundaries we can use a mixture distribution such that the second class is normal with 1/2 odds of mean (20, 10) and sd 20 and 1/2 of mean(20, 40) and sd 60.

```{r}
n = 100  # points per cluster
mu_x1 = 10
mu_y1 = 10
sd1 = 40
mu_x2 = 20
mu_y2 = 10
sd2 = 20
mu_x3 = 20
mu_y3 = 40
sd3 = 60
d1 = mvrnorm(n, mu=c(mu_x1, mu_y1), Sigma=sd1 * diag(2))
d2 = mvrnorm(n, mu=c(mu_x2, mu_y2), Sigma=sd2 * diag(2))
d3 = mvrnorm(n, mu=c(mu_x3, mu_y3), Sigma=sd3 * diag(2))
d = rbind(d1, d2, d3)
d = cbind(d, c(rep(1, n), rep(2, 2 * n)))
colnames(d) = c('x', 'y', 'category')
plot(d[,1:2], col=d[,3], xlab="X", ylab="Y", main="Sample Data", pch=16)
legend("bottomright", c("category 1", "category 2"), col=1:2, pch=16)
```

Split the data and subsets for training and testing.

```{r}
t = sample(1:nrow(d), nrow(d) / 2)
d.train = data.frame(d[t,])
d.test = data.frame(d[-t,])
```


Now we can define functions to perform LOOCV for LDA and tree classification. First LDA:

```{r}
LDAcv = function(train, test) {
  # loop over rows and validate with each one
  # for (i in 1:nrow(train)) {
  #   fit = lda(category ~ ., data = train[-i,])
  #   real = cl[i]
  #   pred = predict(fit, newdata = train[1,])$class
  # }
  fit = lda(category ~ ., data = train, cv = TRUE)
  list(predict(fit, newdata = test)$class, fit)
}
```



Now test the 3 methods. First the LDA:

```{r}
knn_test = KNNcv(d.train[, c("x", "y")], d.test[, c("x", "y")], d.train[, 'category'])
knn_test_preds = knn_test[[1]]
print(paste0('KNN with k=', knn_test[[2]], ' got ', round(sum(knn_test_preds == d.test[, 'category']) / nrow(d.test), digits = 2) * 100, '% correct'))
plot(d.test[, c("x")], d.test[, c("y")], xlab = 'X', ylab = 'Y', pch = as.numeric(d.test[, 'category']) + 1, main = paste('KNN Predictions'))
legend(x = 'topleft', legend = c("Correct", "Incorrect"),  fill = c("green", "red"))
points(d.test[, c("x", "y")], col = ifelse(knn_test_preds == d.test[, 'category'], 'springgreen3', 'tomato'))
```

Next the LDA:

```{r}
lda_test = LDAcv(d.train, d.test)
lda_test_preds = lda_test[[1]]
print(paste0('LDA got ', round(sum(lda_test_preds == d.test[, 'category']) / nrow(d.test), digits = 2) * 100, '% correct'))
plot(d.test[, c("x")], d.test[, c("y")], xlab = 'X', ylab = 'Y', pch = as.numeric(d.test[, 'category']) + 1, main = paste('LDA Predictions'))
legend(x = 'topleft', legend = c("Correct", "Incorrect"),  fill = c("green", "red"))
points(d.test[, c("x", "y")], col = ifelse(lda_test_preds == d.test[, 'category'], 'springgreen3', 'tomato'))
```
Finally we try a decision tree classifier.

```{r}
library(tree)

# classification tree requires a categorical response
d.train[, 'category'] = as.factor(d.train[, 'category'])
d.test[, 'category'] = as.factor(d.test[, 'category'])

fit = tree(category ~ ., data = d.train)
cv = cv.tree(fit, K = nrow(d.train))  # leave-one-out CV
print(cv$dev / length(d.test))
pruned = prune.misclass(fit, best = which.min(cv$dev))
plot(pruned)
text(pruned)
plot(cv$size, cv$dev / nrow(d.test), type = "b", xlab = "Size", ylab = "Error Rate vs. Tree Size")  # https://daviddalpiaz.github.io/r4sl/trees.html
tree_test_preds = predict(pruned, d.test, type = 'class')
print(paste0('Decision Tree got ', round(sum(tree_test_preds == d.test[, 'category']) / nrow(d.test), digits = 2) * 100, '% correct'))
plot(d.test[, c("x")], d.test[, c("y")], xlab = 'X', ylab = 'Y', pch = as.numeric(d.test[, 'category']) + 1, main = paste('Decision Tree Predictions'))
legend(x = 'topleft', legend = c("Correct", "Incorrect"),  fill = c("green", "red"))
points(d.test[, c("x", "y")], col = ifelse(tree_test_preds == d.test[, 'category'], 'springgreen3', 'tomato'))
```

The LDA performs the worst here, although all 3 methods perform relatively similarly.

Next we can try a simpler dataset with a boundary which should be easier to learn, but with the presence of a column of noise which is totally uncorrelated with class.

```{r}
n = 100  # points per cluster
mu_x1 = 10
mu_y1 = 10
sd1 = 40
mu_x3 = 30
mu_y3 = 20
sd3 = 60
d1 = mvrnorm(n, mu=c(mu_x1, mu_y1), Sigma=sd1 * diag(2))
d3 = mvrnorm(n, mu=c(mu_x3, mu_y3), Sigma=sd3 * diag(2))
d = rbind(d1, d3)
d = cbind(d, sample.int(100, n * 2, replace = T), c(rep(1, n), rep(2, n)))
colnames(d) = c('x', 'y', 'noise', 'category')
plot(d[,1:2], col=d[,4], xlab="X", ylab="Y", main="Sample Data", pch=16)
legend("bottomright", c("category 1", "category 2"), col=1:2, pch=16)

t = sample(1:nrow(d), nrow(d) / 2)
d.train = data.frame(d[t,])
d.test = data.frame(d[-t,])
```

We can begin with the LDA this time. First with the noisy column:

```{r}
lda_test = LDAcv(d.train, d.test)
lda_test_preds = lda_test[[1]]
print(paste0('LDA got ', round(sum(lda_test_preds == d.test[, 'category']) / nrow(d.test), digits = 2) * 100, '% correct'))
plot(d.test[, c("x")], d.test[, c("y")], xlab = 'X', ylab = 'Y', pch = as.numeric(d.test[, 'category']) + 1, main = paste('LDA Predictions'))
legend(x = 'topleft', legend = c("Correct", "Incorrect"),  fill = c("green", "red"))
points(d.test[, c("x", "y")], col = ifelse(lda_test_preds == d.test[, 'category'], 'springgreen3', 'tomato'))
```

Next the KNN:

```{r}
knn_test = KNNcv(d.train[, c("x", "y", "noise")], d.test[, c("x", "y", "noise")], d.train[, 'category'])
knn_test_preds = knn_test[[1]]
print(paste0('KNN with k=', knn_test[[2]], ' got ', round(sum(knn_test_preds == d.test[, 'category']) / nrow(d.test), digits = 2) * 100, '% correct'))
plot(d.test[, c("x")], d.test[, c("y")], xlab = 'X', ylab = 'Y', pch = as.numeric(d.test[, 'category']) + 1, main = paste('KNN Predictions'))
legend(x = 'topleft', legend = c("Correct", "Incorrect"),  fill = c("green", "red"))
points(d.test[, c("x", "y")], col = ifelse(knn_test_preds == d.test[, 'category'], 'springgreen3', 'tomato'))
```


Now without the noise, first LDA, then KNN.

```{r}
lda_test = LDAcv(d.train[c('x', 'y', 'category')], d.test[c('x', 'y', 'category')])
lda_test_preds = lda_test[[1]]
print(paste0('LDA (no noise) got ', round(sum(lda_test_preds == d.test[, 'category']) / nrow(d.test), digits = 2) * 100, '% correct'))
plot(d.test[, c("x")], d.test[, c("y")], xlab = 'X', ylab = 'Y', pch = as.numeric(d.test[, 'category']) + 1, main = paste('LDA Predictions (no noise)'))
legend(x = 'topleft', legend = c("Correct", "Incorrect"),  fill = c("green", "red"))
points(d.test[, c("x", "y")], col = ifelse(lda_test_preds == d.test[, 'category'], 'springgreen3', 'tomato'))

knn_test = KNNcv(d.train[, c("x", "y")], d.test[, c("x", "y")], d.train[, 'category'])
knn_test_preds = knn_test[[1]]
print(paste0('KNN (no noise) with k=', knn_test[[2]], ' got ', round(sum(knn_test_preds == d.test[, 'category']) / nrow(d.test), digits = 2) * 100, '% correct'))
plot(d.test[, c("x")], d.test[, c("y")], xlab = 'X', ylab = 'Y', pch = as.numeric(d.test[, 'category']) + 1, main = paste('KNN Predictions (no noise)'))
legend(x = 'topleft', legend = c("Correct", "Incorrect"),  fill = c("green", "red"))
points(d.test[, c("x", "y")], col = ifelse(knn_test_preds == d.test[, 'category'], 'springgreen3', 'tomato'))
```

The KNN improved by a single percentage point, but the LDA's accuracy was unchanged by the removal of the noise variable.
